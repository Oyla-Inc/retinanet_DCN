{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pdb\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "import sys\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from retinanet.dataloader import CocoDataset, CSVDataset, collater, Resizer, AspectRatioBasedSampler, Augmenter, \\\n",
    "\tUnNormalizer, Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retinanet import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "retinanet = model.resnet50(num_classes=80)\n",
    "\n",
    "#retinanet = torch.load('coco_resnet_50_map_0_335_state_dict.pt',map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retinanet.load_state_dict(torch.load('coco_resnet_50_map_0_335_state_dict.pt',map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (fpn): PyramidFeatures(\n",
       "      (P5_1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (P5_upsampled): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (P5_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (P4_1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (P4_upsampled): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (P4_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (P3_1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (P3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (P6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (P7_1): ReLU()\n",
       "      (P7_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (regressionModel): RegressionModel(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act1): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): ReLU()\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act3): ReLU()\n",
       "      (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act4): ReLU()\n",
       "      (output): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (classificationModel): ClassificationModel(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act1): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): ReLU()\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act3): ReLU()\n",
       "      (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act4): ReLU()\n",
       "      (output): Conv2d(256, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (output_act): Sigmoid()\n",
       "    )\n",
       "    (anchors): Anchors()\n",
       "    (regressBoxes): BBoxTransform()\n",
       "    (clipBoxes): ClipBoxes()\n",
       "    (focalLoss): FocalLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retinanet = torch.nn.DataParallel(retinanet)\n",
    "retinanet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('/Users/rsingh/Packages/darknet/data/dog.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tf = tf.ToTensor()(img).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.2235, 0.2275, 0.2353,  ..., 0.5608, 0.3490, 0.2549],\n",
       "          [0.2275, 0.2275, 0.2314,  ..., 0.4863, 0.3294, 0.2275],\n",
       "          [0.2275, 0.2275, 0.2314,  ..., 0.3843, 0.3059, 0.1725],\n",
       "          ...,\n",
       "          [0.6275, 0.6275, 0.6392,  ..., 0.3137, 0.2078, 0.2431],\n",
       "          [0.6314, 0.6275, 0.6118,  ..., 0.3098, 0.2118, 0.2627],\n",
       "          [0.6157, 0.6235, 0.6000,  ..., 0.3137, 0.2000, 0.1961]],\n",
       "\n",
       "         [[0.2275, 0.2314, 0.2392,  ..., 0.3490, 0.1922, 0.2745],\n",
       "          [0.2314, 0.2314, 0.2353,  ..., 0.2941, 0.1961, 0.2745],\n",
       "          [0.2314, 0.2314, 0.2353,  ..., 0.2118, 0.2078, 0.2471],\n",
       "          ...,\n",
       "          [0.6588, 0.6588, 0.6706,  ..., 0.2510, 0.1529, 0.2078],\n",
       "          [0.6627, 0.6588, 0.6431,  ..., 0.2392, 0.1569, 0.2196],\n",
       "          [0.6471, 0.6549, 0.6314,  ..., 0.2431, 0.1412, 0.1529]],\n",
       "\n",
       "         [[0.1961, 0.2000, 0.2078,  ..., 0.1686, 0.1608, 0.1843],\n",
       "          [0.2000, 0.2000, 0.2039,  ..., 0.1373, 0.1608, 0.1804],\n",
       "          [0.2000, 0.2000, 0.2039,  ..., 0.0980, 0.1882, 0.1608],\n",
       "          ...,\n",
       "          [0.7020, 0.7020, 0.7137,  ..., 0.2510, 0.1412, 0.1882],\n",
       "          [0.7059, 0.7020, 0.6863,  ..., 0.2392, 0.1451, 0.2039],\n",
       "          [0.6902, 0.6980, 0.6745,  ..., 0.2431, 0.1294, 0.1373]]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tf.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, classification, transformed_anchors = retinanet(img_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8693, 0.7588, 0.6236, 0.2008, 0.1103, 0.1048, 0.0946, 0.0852, 0.0720,\n",
       "        0.0698, 0.0603, 0.0590, 0.0574, 0.0547, 0.0542, 0.0529, 0.0528],\n",
       "       grad_fn=<MaxBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = np.where(scores.cpu()>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_caption(image, box, caption):\n",
    "\n",
    "\t\tb = np.array(box).astype(int)\n",
    "\t\tcv2.putText(image, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 0), 2)\n",
    "\t\tcv2.putText(image, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 255), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "_labels = open('ms_coco.csv','r').read().splitlines()\n",
    "labels=[]\n",
    "for l in _labels:\n",
    "    labels.append(l.split(',')[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n",
      "bicycle\n",
      "car\n"
     ]
    }
   ],
   "source": [
    "for j in range(idxs[0].shape[0]):\n",
    "\t\t\t\tbbox = transformed_anchors[idxs[0][j], :]\n",
    "\t\t\t\tx1 = int(bbox[0])\n",
    "\t\t\t\ty1 = int(bbox[1])\n",
    "\t\t\t\tx2 = int(bbox[2])\n",
    "\t\t\t\ty2 = int(bbox[3])\n",
    "\t\t\t\tlabel_name = labels[int(classification[idxs[0][j]])]\n",
    "\t\t\t\t#draw_caption(img, (x1, y1, x2, y2), label_name)\n",
    "\n",
    "\t\t\t\t#cv2.rectangle(img, (x1, y1), (x2, y2), color=(0, 0, 255), thickness=2)\n",
    "\t\t\t\tprint(label_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127, 223)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function imsave in module matplotlib.pyplot:\n",
      "\n",
      "imsave(fname, arr, **kwargs)\n",
      "    Save an array as an image file.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    fname : str or PathLike file-like\n",
      "        A path or a Python file-like object to store the image in.\n",
      "        If *format* is not set, then the output format is inferred from the\n",
      "        extension of *fname*, if any, and from :rc:`savefig.format` otherwise.\n",
      "        If *format* is set, it determines the output format.\n",
      "    arr : array-like\n",
      "        The image data. The shape can be one of\n",
      "        MxN (luminance), MxNx3 (RGB) or MxNx4 (RGBA).\n",
      "    vmin, vmax : scalar, optional\n",
      "        *vmin* and *vmax* set the color scaling for the image by fixing the\n",
      "        values that map to the colormap color limits. If either *vmin*\n",
      "        or *vmax* is None, that limit is determined from the *arr*\n",
      "        min/max value.\n",
      "    cmap : str or `~matplotlib.colors.Colormap`, optional\n",
      "        A Colormap instance or registered colormap name. The colormap\n",
      "        maps scalar data to colors. It is ignored for RGB(A) data.\n",
      "        Defaults to :rc:`image.cmap` ('viridis').\n",
      "    format : str, optional\n",
      "        The file format, e.g. 'png', 'pdf', 'svg', ...  The behavior when this\n",
      "        is unset is documented under *fname*.\n",
      "    origin : {'upper', 'lower'}, optional\n",
      "        Indicates whether the ``(0, 0)`` index of the array is in the upper\n",
      "        left or lower left corner of the axes.  Defaults to :rc:`image.origin`\n",
      "        ('upper').\n",
      "    dpi : int\n",
      "        The DPI to store in the metadata of the file.  This does not affect the\n",
      "        resolution of the output image.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(plt.imsave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[6412, 5865,5274,4789,4281,3577,3021,2547,2069,1834, 1397,1251,1051,909,724,684,600,512,467,360,283,223,173,114]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1438c3f98>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogy(y,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
